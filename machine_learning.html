<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Overview</title>
    <style>
        body {
            font-family: sans-serif;
            margin: 20px;
        }

        section {
            margin-bottom: 30px;
            border: 1px solid #ccc;
            padding: 15px;
        }

        h2 {
            color: #333;
            border-bottom: 2px solid #eee;
            padding-bottom: 5px;
        }

        h3 {
            color: #555;
        }

        pre {
            background-color: #f4f4f4;
            padding: 10px;
            overflow-x: auto;
            border: 1px solid #ddd;
        }

        code {
            font-family: monospace;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 10px 0;
        }

        ul {
            list-style-type: disc;
            margin-left: 20px;
        }
    </style>
</head>
<body>

    <section>
        <h2>Introduction to Machine Learning</h2>
        <h3>What is Machine Learning?</h3>
        <p>
            Machine Learning is a field of computer science that enables systems to learn from data without being explicitly programmed.
            In traditional programming, you provide explicit instructions. In machine learning, the system learns the instructions from data.
            Machine Learning is important for solving complex problems, automating tasks, and making predictions.
            It has diverse applications like image recognition, natural language processing, fraud detection, recommendation systems, medical diagnosis, and more.
        </p>
        <img src="ml.png" alt="ML" width="300">
        
    </section>

    <section>
        <h2>Types of Machine Learning</h2>
        <h3>Supervised, Unsupervised, and Reinforcement Learning</h3>

        <h4>Supervised Learning</h4>
        <p>
            Supervised learning involves training a model on labeled data, where the input and the desired output are known.
            Common algorithms include linear regression, logistic regression, support vector machines (SVMs), decision trees, and random forests.
            Examples include predicting housing prices based on features (regression) or classifying emails as spam or not spam (classification).
        </p>
        <img src="supervi.png" alt="Supervised Learning" width="300">

        <h4>Unsupervised Learning</h4>
        <p>
            Unsupervised learning involves training a model on unlabeled data, where the goal is to discover patterns and relationships.
            Common algorithms include clustering (k-means, hierarchical clustering), dimensionality reduction (principal component analysis - PCA), and association rule mining.
            Examples include customer segmentation based on purchasing behavior or anomaly detection in network traffic.
        </p>
        <img src="unsuper.png" alt="Unsupervised Learning" width="300">

        <h4>Reinforcement Learning</h4>
        <p>
            Reinforcement learning involves training an agent to make decisions in an environment to maximize a reward.
            Key concepts include agents, environments, states, actions, rewards, and policies.
            Examples include training a robot to navigate a maze or developing an AI for playing games like chess or Go.
        </p>
        <img src="reinforcemet.png" alt="Reinforcement Learning" width="300">
    </section>

    <section>
        <h2>Key Machine Learning Concepts</h2>
        <h3>Understanding the Fundamentals</h3>
        <p>
            <b>Features:</b> Features are individual measurable properties or characteristics of a phenomenon being observed and are important in ML models.
        </p>
        <p>
            <b>Data Splitting:</b> It is important to split data into training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and prevent overfitting, and the testing set is used to evaluate the model's performance on unseen data.
        </p>
        <p>
            <b>Overfitting and Underfitting:</b> Overfitting occurs when a model learns the training data too well, resulting in poor performance on unseen data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data.
        </p>
        <p>
            <b>Bias and Variance:</b> High bias can cause a model to miss relevant relations between features and target outputs. High variance can cause overfitting.
        </p>
        <p>
            <b>Evaluation Metrics:</b> Common evaluation metrics for different types of ML problems include:
            <ul>
                <li>Regression: Mean Squared Error (MSE), R-squared</li>
                <li>Classification: Accuracy, Precision, Recall, F1-score, ROC AUC</li>
            </ul>
        </p>
        <img src="overfit.png" alt="Overfitting Underfitting" width="300">
        <img src="bias.png" alt="Bias Variance" width="300">
    </section>

    <section>
        <h2>Supervised Learning in Detail</h2>
        <h3>Diving Deeper into Supervised Learning</h3>

        <h4>Linear Regression</h4>
        <p>
            The goal of linear regression is to find the best-fitting line that minimizes the sum of squared errors between the predicted and actual values.
            The linear regression equation is: <code>y = mx + b</code> (or the multivariable version).
        </p>
        <pre>
            <code>
from sklearn.linear_model import LinearRegression
import numpy as np

# Sample data
X = np.array([[1], [2], [3], [4], [5]])  # Input feature
y = np.array([2, 4, 5, 4, 5])  # Target variable

# Create and fit the model
model = LinearRegression()
model.fit(X, y)

# Make predictions
new_X = np.array([[6]])
prediction = model.predict(new_X)
print(f"Prediction for X=6: {prediction[0]}")
            </code>
        </pre>
        <img src="linear.png" alt="Linear Regression" width="300">

        <h4>Logistic Regression</h4>
        <p>
            Logistic regression is used for binary classification problems. The sigmoid function plays a key role in predicting probabilities.
        </p>
        <pre>
            <code>
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Sample data (replace with your actual data)
X = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])  # Input features
y = np.array([0, 0, 0, 1, 1, 1])  # Target variable (0 or 1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create and fit the model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
            </code>
        </pre>
        <img src="logistic.png" alt="Logistic Regression" width="300">
        <img src="sigmoid_function.png" alt = "Sigmoid Function" width = "300">
    </section>

    <section>
        <h2>More Supervised Learning Algorithms</h2>
        <h3>Exploring Advanced Supervised Learning Methods</h3>

        <h4>Support Vector Machines (SVMs)</h4>
        <p>
            SVMs find the optimal hyperplane to separate data points. Different kernel functions (linear, polynomial, RBF) can be used.
        </p>
        <pre>
            <code>
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Sample data (replace with your actual data)
X = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])  # Input features
y = np.array([0, 0, 0, 1, 1, 1])  # Target variable (0 or 1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create and fit the model
model = SVC(kernel='linear')  # You can change the kernel
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
            </code>
        </pre>
        <img src="svm.png" alt="SVM" width="300">

        <h4>Decision Trees</h4>
        <p>
            Decision trees recursively partition the data based on feature values, using splitting criteria like Gini impurity or information gain.
        </p>
        <pre>
            <code>
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Sample data (replace with your actual data)
X = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])  # Input features
y = np.array([0, 0, 0, 1, 1, 1])  # Target variable (0 or 1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create and fit the model
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
            </code>
        </pre>
        <img src="decision tree.png" alt="Decision Tree" width="300">

        <h4>Random Forests</h4>
        <p>
            Random forests combine multiple decision trees to improve accuracy and reduce overfitting, using techniques like bagging and feature randomness.
        </p>
        <pre>
            <code>
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Sample data (replace with your actual data)
X = np.array([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])  # Input features
y = np.array([0, 0, 0, 1, 1, 1])  # Target variable (0 or 1)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create and fit the model
model = RandomForestClassifier(n_estimators=100)  # You can adjust the number of trees
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
            </code>
        </pre>
        <img src="random.png" alt="Random Forest" width="300">
    </section>

    <section>
        <h2>Unsupervised Learning in Detail</h2>
        <h3>Exploring Patterns with Unsupervised Learning</h3>

        <h4>Clustering (K-Means)</h4>
        <p>
            K-means clustering aims to partition data points into k clusters, where each point belongs to the cluster with the nearest mean (centroid).
            The process involves initializing centroids and iteratively assigning points to clusters and updating centroids.
        </p>
        <pre>
            <code>
from sklearn.cluster import KMeans
import numpy as np

# Sample data
X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])

# Create and fit the model
kmeans = KMeans(n_clusters=2, random_state=0, n_init = 'auto')  # Specify the number of clusters
kmeans.fit(X)

# Get cluster assignments and centroids
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

print("Cluster labels:", labels)
print("Centroids:", centroids)
            </code>
        </pre>
        <img src="kmeans.png" alt="K-Means Clustering" width="300">

        <h4>Dimensionality Reduction (PCA)</h4>
        <p>
            PCA aims to reduce the number of features while preserving the most important information.
            It identifies principal components that capture the most variance in the data.
        </p>
        <pre>
            <code>
from sklearn.decomposition import PCA
import numpy as np

# Sample data
X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

# Create and apply PCA
pca = PCA(n_components=2)  # Specify the number of components to keep
pca.fit(X)

# Transform the data
transformed_X = pca.transform(X)

print("Original data shape:", X.shape)
print("Transformed data shape:", transformed_X.shape)
            </code>
        </pre>
        <img src="pca.png" alt="PCA" width="300">
    </section>

    <section>
        <h2>Reinforcement Learning Basics</h2>
        <h3>Training Agents Through Interaction</h3>

        <h4>Key Concepts</h4>
        <ul>
            <li><b>Agent:</b> The learner that interacts with the environment.</li>
            <li><b>Environment:</b> The world in which the agent operates.</li>
            <li><b>State:</b> The current situation of the agent.</li>
            <li><b>Action:</b> A choice the agent can make.</li>
            <li><b>Reward:</b> Feedback from the environment after an action.</li>
            <li><b>Policy:</b> A strategy that the agent uses to determine which action to take in each state.</li>
        </ul>

        <h4>Q-Learning</h4>
        <p>
            Q-learning is a reinforcement learning algorithm that learns a Q-function, which estimates the expected reward for taking a particular action in a particular state.
            It uses a Q-table to store the Q-values.
        </p>
        <p>
            The Q-learning update rule is: <code>Q(s, a) = Q(s, a) + α [R(s, a) + γ max Q(s', a') - Q(s, a)]</code>
            <ul>
                <li>α is the learning rate</li>
                <li>γ is the discount factor</li>
                <li>s' is the next state</li>
                <li>a' is the next action</li>
            </ul>
        </p>
        <pre>
            <code>
import numpy as np

# Define the environment (simplified)
states = [0, 1, 2, 3]
actions = [0, 1]  # Example: 0 - Left, 1 - Right
rewards = {(0, 0): -1, (0, 1): 0, (1, 0): 0, (1, 1): -1, (2, 0): 0, (2, 1): 10, (3, 0): -1, (3, 1): -1}  # (state, action): reward
next_state = {(0, 0): 0, (0, 1): 1, (1, 0): 0, (1, 1): 1, (2, 0): 2, (2, 1): 3, (3, 0): 3, (3, 1): 3}

# Initialize Q-table
q_table = np.zeros((len(states), len(actions)))

# Q-Learning parameters
alpha = 0.1  # Learning rate
gamma = 0.9  # Discount factor
episodes = 100

# Q-Learning algorithm
for _ in range(episodes):
    state = np.random.choice(states)  # Start in a random state

    for _ in range(10): # Small steps
        # Choose an action (for simplicity, always exploit)
        action = np.argmax(q_table[state, :])

        # Get the reward and next state
        reward = rewards[(state, action)]
        next_state_val = next_state[(state, action)]

        # Update Q-value
        best_next_action = np.argmax(q_table[next_state_val, :])
        q_table[state, action] = q_table[state, action] + alpha * (reward + gamma * q_table[next_state_val, best_next_action] - q_table[state, action])

        # Move to the next state
        state = next_state_val

print("Q-table:")
print(q_table)
            </code>
        </pre>
        <img src = "q.png" alt = "Q Learning" width="300">
    </section>

    <section>
        <h2>Model Selection and Training</h2>
        <h3>Choosing the Right Model and Training It Effectively</h3>

        <h4>Model Selection</h4>
        <p>
            Selecting the right model is crucial for achieving good performance. Consider factors like the type of problem, the size and nature of the data, and the interpretability requirements.
        </p>
        <ul>
            <li><b>Consider the problem type:</b> Choose classification models for classification tasks and regression models for regression tasks.</li>
            <li><b>Understand the data:</b> Explore the data to understand its characteristics, such as the number of features, the presence of missing values, and the distribution of the target variable.</li>
            <li><b>Consider model complexity:</b> Start with simpler models and gradually increase complexity if needed.</li>
            <li><b>Consider interpretability:</b> If interpretability is important, choose models that are easy to understand, such as linear regression or decision trees.</li>
        </ul>

        <h4>Training Process</h4>
        <p>
            The training process involves feeding the model with data and adjusting its parameters to minimize the error.
        </p>
        <ul>
            <li><b>Data Preprocessing:</b> Clean and prepare the data by handling missing values, scaling features, and encoding categorical variables.</li>
            <li><b>Feature Engineering:</b> Create new features from existing ones to improve model performance.</li>
            <li><b>Hyperparameter Tuning:</b> Optimize the model's hyperparameters using techniques like grid search or random search.</li>
            <li><b>Cross-Validation:</b> Use cross-validation to evaluate the model's performance on multiple subsets of the data.</li>
        </ul>
         <img src = "modelselecgt.png" alt = "model selection" width="300">
    </section>

    <section>
        <h2>Evaluation and Deployment</h2>
        <h3>Assessing Model Performance and Putting It into Action</h3>

        <h4>Model Evaluation</h4>
        <p>
            Evaluating the model's performance is essential to ensure that it generalizes well to unseen data.
        </p>
        <ul>
            <li><b>Choose appropriate metrics:</b> Select evaluation metrics that are relevant to the problem and the business goals.</li>
            <li><b>Use a hold-out set:</b> Evaluate the model on a hold-out set that was not used during training or validation.</li>
            <li><b>Consider different evaluation scenarios:</b> Evaluate the model under different conditions to assess its robustness.</li>
        </ul>

        <h4>Model Deployment</h4>
        <p>
            Deploying the model involves making it available for use in a real-world application.
        </p>
        <ul>
            <li><b>Choose a deployment platform:</b> Select a deployment platform that meets the requirements of the application, such as cloud-based platforms or on-premise servers.</li>
            <li><b>Integrate the model with the application:</b> Integrate the model with the application by creating an API or embedding the model directly into the application code.</li>
            <li><b>Monitor the model's performance:</b> Monitor the model's performance over time to detect any degradation and retrain the model if necessary.</li>
        </ul>
          <img src = "eval.png" alt = "Model Evaluation" width="300">
    </section>

    <section>
        <h2>Ethical Considerations and Future Trends</h2>
        <h3>Addressing Ethical Concerns and Looking Ahead</h3>

        <h4>Ethical Considerations</h4>
        <p>
            Machine learning models can have a significant impact on society, so it's important to consider the ethical implications of their use.
        </p>
        <ul>
            <li><b>Bias:</b> Address bias in the data and the model to ensure fairness and prevent discrimination.</li>
            <li><b>Transparency:</b> Make the model's decision-making process transparent and explainable.</li>
            <li><b>Accountability:</b> Establish accountability for the model's decisions and actions.</li>
        </ul>

        <h4>Future Trends</h4>
        <p>
            The field of machine learning is constantly evolving, with new algorithms and techniques being developed all the time.
        </p>
        <ul>
            <li><b>Deep Learning:</b> Deep learning is a rapidly growing field that has achieved state-of-the-art results on many tasks.</li>
            <li><b>Explainable AI (XAI):</b> XAI aims to make machine learning models more transparent and understandable.</li>
            <li><b>Federated Learning:</b> Federated learning enables training models on decentralized data without sharing the data itself.</li>
        </ul>
    
    </section>

</body>
</html>
